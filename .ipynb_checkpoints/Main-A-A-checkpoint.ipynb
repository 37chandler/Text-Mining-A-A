{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining - Acquire and Analyze\n",
    "# AJ Eckmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "For this aquire and analyze I will be using data that I acquired for one of my data set shares. This data set that I created comes from transcripts of all the office episodes ever made. The base transcripts can be found and downloaded from GitHub at: https://github.com/brianbuie/the-office.\n",
    "\n",
    "I was actually given the idea to look for this data from seeing Maryâ€™s data set share on the Friends transcripts. I am a big fan of the office and thought it would be a cool dataset to look at. Instead of looking at differences between episodes/seasons, I thought a cool analysis would be to look at the differences between characters.\n",
    "\n",
    "In my initial data set share, I just created a dictionary for each of the office characters and appended all of the tokens that they said throughout the show. In this Acquire and Analyze, I take this a couple steps further. In addition to just looking at all the tokens (words) that each character says, I want to also be able to differentiate between seasons of the show. To do this I will need to re-format the inital dictionaries that I created in the data set share.\n",
    "\n",
    "The purpose of this acquire and analyze is to take this previously messy json data, and turn it into interpretable code to analyze the sentiments and usage of all of the office characters throughout the course of the show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data and Analysis\n",
    "\n",
    "In this section I will format the data that I am using and also talk through some of my code/thought process on how to go about formatting the data so that I am able to analyze the sentiment of characters.\n",
    "\n",
    "In the initial data share, I only sorted out the data by character. In this A&A I took this a step further and sorted it out by character, by season and episode, so that I could look more closely on some of the changes in sentiment and useage over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the filenames from the eplib (episode library) \n",
    "fileList = []\n",
    "for filenames in os.walk('eplib'):\n",
    "    for li in filenames[2]:\n",
    "        fileList.append(li)\n",
    "\n",
    "#create a list of dictionaries for each scene\n",
    "scenes = []\n",
    "for file in fileList:\n",
    "    path = \"eplib/\"\n",
    "    fil = path + file\n",
    "    with open(fil, encoding='utf-8', mode='r') as currentFile:\n",
    "        rd = currentFile.read()\n",
    "        title = json.loads(rd)[\"title\"]\n",
    "        scen = json.loads(rd)[\"scenes\"]\n",
    "        \n",
    "        ##This part is all about breaking up the json\n",
    "        ##scen is a list of dictionaries that I itterate though\n",
    "        ##char is each dictionary in this list, each of these dictionaries maps 1 to 1 with a character\n",
    "        ##unlike in my data share, I redesigned this part to include season and episode in the dict so I can use that later\n",
    "        \n",
    "        for part in scen:\n",
    "            for char in part:\n",
    "                scene_dict = char\n",
    "                scene_dict[\"season\"] = json.loads(rd)[\"season\"]\n",
    "                scene_dict[\"episode\"] = json.loads(rd)[\"episode\"]\n",
    "                scenes.append(scene_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, I now have to take a list of nested dictionaries that I created above from the json files, and turn them into something workable for my analysis. The best way that I could come up with of doing this is by creating a triple nested dictionary. It sounds inneficient and hard to keep track of, but when I have to iterate through 700 different characters' transcripts later on, this methods proves to be very efficient.\n",
    "\n",
    "The structure of the nested dictionaries is:\n",
    "\n",
    "chardict (main dictionary, keys are characters)\n",
    "season_dict (there is one of these dictionaries for each of the 700 characters, the keys to this dictionary are the seasons of the show (1-9) that this character had lines in)\n",
    "episode_dict (this is the lowest level of dicitonary in this section, there is one of these dictionaries for each season for every character, the keys to this dictionary are episodes)\n",
    "\n",
    "For example, a call to chardict['Michael'] might return:\n",
    "\n",
    "{'season 1': { 'episode 1' : 'Hello, my name is Michael Scott', 'episode 2' : 'How are you...' } , 'season 2' : { 'episode 1' :...} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize dictionary and iterate through the scene dictionaries\n",
    "chardict = {}\n",
    "for pers in scenes:\n",
    "    new_char = pers['character']\n",
    "    new_season = pers['season']\n",
    "    new_episode = pers['episode']\n",
    "    lines = pers['line'].split(\" \")\n",
    "    \n",
    "    #adding characters to the dictionary for the first time\n",
    "    if new_char not in chardict:    \n",
    "        season_dict = {}\n",
    "        episode_dict = {}\n",
    "        episode_dict[new_episode] = lines\n",
    "        season_dict[new_season] = episode_dict\n",
    "        chardict[new_char] = season_dict\n",
    "    \n",
    "    #if character already in the dictionary\n",
    "    else:      \n",
    "        #if they don't already have a dictionary for this season, create one\n",
    "        if new_season not in chardict[new_char]:\n",
    "            episode_dict = {}\n",
    "            episode_dict[new_episode] = lines\n",
    "            #person_dict[new_season] = episode_dict\n",
    "            chardict[new_char][new_season] = episode_dict\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            #if they haven't already spoken in this episode, we need to create a new episode entry\n",
    "            if new_episode not in chardict[new_char][new_season]:\n",
    "                chardict[new_char][new_season][new_episode] = lines\n",
    "            \n",
    "            else:\n",
    "                chardict[new_char][new_season][new_episode].extend(lines)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 620192 total words in the transcripts\n",
      "There are 700 different characters with lines in this dataset\n"
     ]
    }
   ],
   "source": [
    "#Just a little eda... creating a dictionary of all the characters and how many words they spoke\n",
    "#also counting how many words total (620,192)\n",
    "bigl = {}\n",
    "tot = 0\n",
    "for pers in chardict.keys():\n",
    "    pers_words = 0\n",
    "    for seas in chardict[pers]:\n",
    "        for ep in chardict[pers][seas]:\n",
    "            tot += len(chardict[pers][seas][ep])\n",
    "            pers_words += len(chardict[pers][seas][ep])\n",
    "    bigl[pers] = pers_words \n",
    "    \n",
    "print(\"There are \" + str(tot) + \" total words in the transcripts\")\n",
    "print(\"There are \" + str(len(chardict)) + \" different characters with lines in this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting characters by how many words they said\n",
    "import operator\n",
    "sorted_char = sorted(bigl.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Michael', 159101),\n",
       " ('Dwight', 82739),\n",
       " ('Jim', 62394),\n",
       " ('Pam', 48203),\n",
       " ('Andy', 47671),\n",
       " ('Angela', 14574),\n",
       " ('Erin', 14090),\n",
       " ('Kevin', 13887),\n",
       " ('Oscar', 12830),\n",
       " ('Ryan', 12678),\n",
       " ('Darryl', 12291),\n",
       " ('Kelly', 9696),\n",
       " ('Jan', 8351),\n",
       " ('Toby', 8349),\n",
       " ('Phyllis', 8019),\n",
       " ('Nellie', 7184),\n",
       " ('Robert California', 6234),\n",
       " ('Gabe', 6153),\n",
       " ('Stanley', 6109),\n",
       " ('David Wallace', 5310),\n",
       " ('Holly', 5099),\n",
       " ('Meredith', 4750),\n",
       " ('Creed', 4327),\n",
       " ('Deangelo', 3823),\n",
       " ('Jo', 3111)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorted character list by total words, printing top 25 for space reasons\n",
    "sorted_char[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing that I want to look at is the breakdown of total tokens and total characters by season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_seasons = {}\n",
    "season_count = {'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
    "only_once = 0\n",
    "for char in chardict:\n",
    "    szn_count = len(chardict[char])\n",
    "    if szn_count == 1:\n",
    "        only_once += 1\n",
    "    szn_list = [szn_count]\n",
    "    empty_list = [0,0,0,0,0,0,0,0,0]\n",
    "    for seas in chardict[char]:\n",
    "        empty_list[int(seas)-1] = 1\n",
    "        season_count[str(seas)] += 1\n",
    "    szn_list.append(empty_list)\n",
    "    character_seasons[char] = szn_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I printed the character_seasons output for Micheal Scott. Michael was the main character, but left the show after season 7. However, he did return during the very last episode of season 9, which is reflected in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, [1, 1, 1, 1, 1, 1, 1, 0, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_seasons['Michael']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool case here is with a character like Holly, who appears in 3 non-consecutive seasons, all of this data checks out with the activities of the show which is cool to see given the complexity of digging through the character layers of the json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, [0, 0, 0, 1, 1, 0, 1, 0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_seasons['Holly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code chunk above I also created a dictionary that counted how many unique characters appeared in each of the 9 seasons. Note that season 1 was only 6 episodes, and season 4 was only 14 episodes, while the rest of the seasons were ~20 episodes long. This would indicate that the more episodes in a season, would result in more unique characters, which is pretty obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 29,\n",
       " '2': 116,\n",
       " '3': 102,\n",
       " '4': 96,\n",
       " '5': 125,\n",
       " '6': 139,\n",
       " '7': 142,\n",
       " '8': 124,\n",
       " '9': 184}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also ran a counter on the number of characters that only appeared in 1 of the 9 seasons. Interestingly enough, 569 of the 700 characters only appeared in 1 of the 9 seasons. This is a much higher number than I would've expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will prepare the data to do some sentiment analysis on the trascripts of these characters and see if we can draw any insigts from the most positive/negative characters or just the general sentiment of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all the words spoken for each character, no more breakdown by season\n",
    "scenes2 = []\n",
    "for file in fileList:\n",
    "    path = \"eplib/\"\n",
    "    fil = path + file\n",
    "    with open(fil, encoding='utf-8', mode='r') as currentFile:\n",
    "        rd = currentFile.read()\n",
    "        title = json.loads(rd)[\"title\"]\n",
    "        scen = json.loads(rd)[\"scenes\"]\n",
    "        for part in scen:\n",
    "            scenes2.append(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now going through the new list of all the words spoken (no longer broken down by season) and\n",
    "# recreating the dictionary, mapping a character to all their words\n",
    "\n",
    "chardict = {}\n",
    "for part in scenes2:\n",
    "    for pers in part:\n",
    "        if pers['character'] not in chardict:\n",
    "            new = pers['character']\n",
    "            line = pers['line'].split(\" \")\n",
    "            chardict[new] = line\n",
    "        else:\n",
    "            new = pers['character']\n",
    "            line = pers['line'].split(\" \")\n",
    "            chardict[new].extend(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you dig deeper into these json files, or the output from the dictionary above, you will notice there is one large problem when trying to analyze the spoken words from these characters solely based on transcript output attributed to them.\n",
    "\n",
    "This problem is that, unspoken actions are also included in the trascript, mixed in with the spoken words. In order to do a proper sentiment analysis I have to deal with this problem. Fortunately all of these unspoken actions are enclosed with '[ ]'. This makes it easier to identify these unspoken actions. Now we have to iterate through the trascript and search for the opening and closing square brackets and exclude all the text between the two from our analysis.\n",
    "\n",
    "An example of this would be:\n",
    "{'Michael' : 'Hey, how are you doing? I'm [shakes his hand] doing well.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I create a new dicitonary \"talk_only\", that excludes these unspoken lines\n",
    "talk_only = {}\n",
    "for char in chardict:\n",
    "    \n",
    "    #initializing a list of indexes of words that are unspoken so I can delete them in the end\n",
    "    dele_list = []\n",
    "    talk = chardict[char]\n",
    "    leng = len(talk)\n",
    "    for word in range(0,len(talk)):\n",
    "        \n",
    "        #make sure that we didn't index incorrectly\n",
    "        if talk[word] == '':\n",
    "            dele_list.append(word)\n",
    "        \n",
    "        #If a word is the start of this unspoken piec\n",
    "        elif talk[word][0] == '[':\n",
    "            #If it's also the end, just delete that word\n",
    "            if talk[word][-1] == ']':\n",
    "                dele_list.append(word)\n",
    "                break\n",
    "            #otherwise, keep going till the end of the transcript until we find the end of the unspoken\n",
    "            else:\n",
    "                for end in range(word,len(talk)):\n",
    "                    if talk[end][-1] == ']':\n",
    "                        dele_list.append(end)\n",
    "                        break\n",
    "                    else:\n",
    "                        dele_list.append(end) \n",
    "                        \n",
    "    #now delete all the indexes (in reverse so the indices don't change on us)\n",
    "    for i in sorted(dele_list, reverse=True):\n",
    "        del talk[i]\n",
    "    \n",
    "    #now go through and reformat the words that are actually spoken\n",
    "    \n",
    "    sw = stopwords.words(\"english\")\n",
    "    \n",
    "    talk = map(str.strip, talk) \n",
    "    \n",
    "    further = [w.lower() for w in talk if w.lower() not in sw and w.isalpha()]\n",
    "    \n",
    "    #reassign the new list to the character as their talk only (and correctly formatted text)\n",
    "    \n",
    "    talk_only[char] = further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right',\n",
       " 'quarterlies',\n",
       " 'look',\n",
       " 'things',\n",
       " 'come',\n",
       " 'master',\n",
       " 'let',\n",
       " 'show',\n",
       " 'like',\n",
       " 'speak',\n",
       " 'office',\n",
       " 'michael',\n",
       " 'regional',\n",
       " 'manager',\n",
       " 'dunder',\n",
       " 'mifflin',\n",
       " 'paper',\n",
       " 'wanted',\n",
       " 'talk',\n",
       " 'done',\n",
       " 'thank',\n",
       " 'gentleman',\n",
       " 'woman',\n",
       " 'talking',\n",
       " 'low']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just a quick check to make sure we got rid of sw, stripped the lines and everything is lowecase\n",
    "talk_only['Michael'][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a file and code from earlier in the semester to classify each of these words as +/- on a 1/-1 scale\n",
    "\n",
    "sentiment_scores = {}\n",
    "            \n",
    "# Open the file `tidytext_sentiments.txt`\n",
    "# Fill up sentiment scores so it has values like \n",
    "# sentiment_scores['awesome'] = 1\n",
    "\n",
    "with open(\"tidytext_sentiments.txt\", \"r\") as infile:\n",
    "    next(infile)\n",
    "    for line in infile.readlines():\n",
    "        line = line.strip().split()\n",
    "        word = line[0]\n",
    "        if line[1] == \"negative\":\n",
    "            sentiment_scores[word] = -1\n",
    "        elif line[1] == \"positive\":\n",
    "            sentiment_scores[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the sentiment of the characters, I wanted to look at more than just a total sentiment score. Looking at only the sentiment score here seemed flawed for a couple reasons. Firstly, looking at only the sentiment score (when scored on the 1/-1 scale) you get no context for how many words are being spoken. If the show is relatively happy, the character with the highest sentiment score will most likely be the person who talks the most. The way that I tried to account for this project was instead of only calculating a sentiment score for each character, I created a dictionary for each character. In this dictionary I stored the sentiment score, positive words, negative words, total words, average sentiment per word (sentiment score/total words), percent of words that were positive and percent of words that were negative. I also included an 'emotion' variable, which is simply what % of a characters words were classified as either positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_sent = {}\n",
    "for pers in talk_only:\n",
    "    totals = {'sentiment':0,'positive':0,'negative':0,'total_words':0,'Avg_sent':0,'Pct_Pos':0,'Pct_Neg':0, 'Emotion' : 0}\n",
    "    for word in talk_only[pers]:\n",
    "        totals['total_words'] += 1\n",
    "        if word in sentiment_scores:\n",
    "            sco = sentiment_scores[word]\n",
    "            totals['sentiment'] += sco\n",
    "            if sco == 1:\n",
    "                totals['positive'] += 1\n",
    "            if sco == -1:\n",
    "                totals['negative'] += 1\n",
    "    \n",
    "    if totals['total_words'] > 0:\n",
    "        totals['Avg_sent'] = round(totals['sentiment'] / totals['total_words'],3)\n",
    "        totals['Pct_Pos'] = round(totals['positive'] / totals['total_words'],3)\n",
    "        totals['Pct_Neg'] = round(totals['negative'] / totals['total_words'],3)\n",
    "        totals['Emotion'] = round((totals['negative'] + totals['positive'] ) /totals['total_words'],3)\n",
    "    \n",
    "    char_sent[pers] = totals\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample of the output from the char_sent dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 3172,\n",
       " 'positive': 6196,\n",
       " 'negative': 3024,\n",
       " 'total_words': 42278,\n",
       " 'Avg_sent': 0.075,\n",
       " 'Pct_Pos': 0.147,\n",
       " 'Pct_Neg': 0.072,\n",
       " 'Emotion': 0.218}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_sent['Michael']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I print the sorted values for the average emotion, percent negative, percent positive, and % emotion words. In the dicionaries that I create, I am filtering only the characters who speak > 1000 words to filter out the characters who may have only spoken a sentence or two that was havily positive or negative. This will also allow us to see both ends of the spectrum in the same print. In addition to the prints, I create dictionaries for the 'Avg_sent', 'Pct_Post', 'Pct_Neg' and 'Emotion'. These dictionaries take a character as a key and the value is a list of their ranks in these different sorted lists.\n",
    "\n",
    "In this first code block and print, we can see that the character with the highest sentiment is David Wallace. He only appears in a a couple seasons of the show, but is generally up positive and happy, hence the high score. Second highest sentiment score was Ryan, which also makes sense, while he is not a super up-beat character, he is always talking about big ideas and business plans that he has and is generally in very good spirits. The next 3 characters are Holly, Pam, Phyllis who are all very cheery and generally happy characters.\n",
    "\n",
    "The worst sentiment score (notably, with a score still > 0), was Meredith. She is portrayed in the show as having a pretty tough life and a lot of things go wrong for her so this score makes sense. The next lowest characters are Creed, Dwight, Kelly, Gabe and Stanley. This group of characters is typically the brutally honest and pesimistic group, so this scoring makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Wallace 0.091\n",
      "Ryan 0.087\n",
      "Holly 0.083\n",
      "Pam 0.079\n",
      "Phyllis 0.077\n",
      "Angela 0.077\n",
      "Michael 0.075\n",
      "Jim 0.073\n",
      "Andy 0.071\n",
      "Erin 0.07\n",
      "Nellie 0.07\n",
      "Jan 0.069\n",
      "Robert California 0.069\n",
      "Deangelo 0.069\n",
      "Kevin 0.066\n",
      "Oscar 0.06\n",
      "Toby 0.06\n",
      "Darryl 0.06\n",
      "Stanley 0.055\n",
      "Gabe 0.054\n",
      "Kelly 0.05\n",
      "Dwight 0.049\n",
      "Creed 0.045\n",
      "Meredith 0.028\n"
     ]
    }
   ],
   "source": [
    "top_sents = {}\n",
    "\n",
    "for char in char_sent:\n",
    "    if char_sent[char]['total_words'] > 1000:\n",
    "        top_sents[char] = char_sent[char]['Avg_sent']\n",
    "\n",
    "sort_sent = sorted(top_sents.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in sort_sent:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I print and create the dictionary for the percent of negative words. Unsurprisingly, this list is very close to a reversed list of the sentiment score printed above. Below that is the printed rankings by percent positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meredith 0.1\n",
      "Kelly 0.089\n",
      "Dwight 0.086\n",
      "Creed 0.086\n",
      "Gabe 0.084\n",
      "Nellie 0.084\n",
      "Stanley 0.078\n",
      "Andy 0.077\n",
      "Oscar 0.076\n",
      "Angela 0.076\n",
      "Toby 0.076\n",
      "Robert California 0.076\n",
      "Darryl 0.074\n",
      "Michael 0.072\n",
      "Jan 0.072\n",
      "Holly 0.07\n",
      "Deangelo 0.07\n",
      "Kevin 0.069\n",
      "Erin 0.068\n",
      "Jim 0.063\n",
      "David Wallace 0.061\n",
      "Pam 0.06\n",
      "Phyllis 0.058\n",
      "Ryan 0.058\n"
     ]
    }
   ],
   "source": [
    "top_neg = {}\n",
    "\n",
    "for char in char_sent:\n",
    "    if char_sent[char]['total_words'] > 1000:\n",
    "        top_neg[char] = char_sent[char]['Pct_Neg']\n",
    "        \n",
    "sort_neg = sorted(top_neg.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in sort_neg:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angela 0.153\n",
      "Holly 0.153\n",
      "Nellie 0.153\n",
      "David Wallace 0.152\n",
      "Andy 0.149\n",
      "Michael 0.147\n",
      "Ryan 0.145\n",
      "Robert California 0.145\n",
      "Jan 0.141\n",
      "Kelly 0.14\n",
      "Pam 0.139\n",
      "Deangelo 0.139\n",
      "Erin 0.138\n",
      "Gabe 0.138\n",
      "Oscar 0.136\n",
      "Toby 0.136\n",
      "Jim 0.135\n",
      "Dwight 0.135\n",
      "Phyllis 0.135\n",
      "Kevin 0.135\n",
      "Stanley 0.134\n",
      "Darryl 0.134\n",
      "Creed 0.131\n",
      "Meredith 0.128\n"
     ]
    }
   ],
   "source": [
    "top_pos = {}\n",
    "\n",
    "for char in char_sent:\n",
    "    if char_sent[char]['total_words'] > 1000:\n",
    "        top_pos[char] = char_sent[char]['Pct_Pos']\n",
    "        \n",
    "sort_pos = sorted(top_pos.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in sort_pos:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly I print the result of the emotion variable that I created. I created this varible as a way to see what % of the characters transcript had words that were emotion based (positive or negative), this could show the characters that show the most emotions, not necessarily positive or negative. Note that here I am only using total words that aren't in stop words from the lists created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nellie 0.237\n",
      "Angela 0.229\n",
      "Kelly 0.229\n",
      "Meredith 0.227\n",
      "Andy 0.226\n",
      "Holly 0.223\n",
      "Gabe 0.222\n",
      "Dwight 0.221\n",
      "Robert California 0.221\n",
      "Michael 0.218\n",
      "Creed 0.218\n",
      "Jan 0.213\n",
      "Toby 0.213\n",
      "David Wallace 0.213\n",
      "Stanley 0.212\n",
      "Oscar 0.212\n",
      "Deangelo 0.209\n",
      "Darryl 0.208\n",
      "Erin 0.207\n",
      "Kevin 0.205\n",
      "Ryan 0.202\n",
      "Pam 0.2\n",
      "Jim 0.198\n",
      "Phyllis 0.193\n"
     ]
    }
   ],
   "source": [
    "emot = {}\n",
    "\n",
    "for char in char_sent:\n",
    "    if char_sent[char]['total_words'] > 1000:\n",
    "        emot[char] = char_sent[char]['Emotion']\n",
    "\n",
    "sort_emot = sorted(emot.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in sort_emot:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the people who appear at the top of the emotions variable rank are the characters who were at the very top (Angela, Holly) and very bottom (Kelly, Meredith, Gabe, Dwight) of the average sentiment rankings.\n",
    "\n",
    "Next, I created dictionaries to store the characters ranks in each of these four rankings I created above. I store these 4 answers as a list, and then also classify people as 'positive' or 'negative' if their ranking in one of the categories is >= 5, the other ranking. The output of this dictionary is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Angela': [1, 10, 2, 9, 'Positive'], 'Holly': [2, 16, 6, 14, 'Positive'], 'Nellie': [3, 6, 1, 3, ''], 'David Wallace': [4, 21, 14, 17, 'Positive'], 'Andy': [5, 8, 5, 3, ''], 'Michael': [6, 14, 10, 8, 'Positive'], 'Ryan': [7, 24, 21, 17, 'Positive'], 'Robert California': [8, 12, 9, 4, ''], 'Jan': [9, 15, 12, 6, 'Positive'], 'Kelly': [10, 2, 3, -8, 'Negative'], 'Pam': [11, 22, 22, 11, 'Positive'], 'Deangelo': [12, 17, 17, 5, 'Positive'], 'Erin': [13, 19, 19, 6, 'Positive'], 'Gabe': [14, 5, 7, -9, 'Negative'], 'Oscar': [15, 9, 16, -6, 'Negative'], 'Toby': [16, 11, 13, -5, 'Negative'], 'Jim': [17, 20, 23, 3, ''], 'Dwight': [18, 3, 8, -15, 'Negative'], 'Phyllis': [19, 23, 24, 4, ''], 'Kevin': [20, 18, 20, -2, ''], 'Stanley': [21, 7, 15, -14, 'Negative'], 'Darryl': [22, 13, 18, -9, 'Negative'], 'Creed': [23, 4, 11, -19, 'Negative'], 'Meredith': [24, 1, 4, -23, 'Negative']}\n"
     ]
    }
   ],
   "source": [
    "char_ranks = {}\n",
    "final_emot_rk = {}\n",
    "\n",
    "for rank, pers in enumerate(sort_pos):\n",
    "    char_ranks[pers[0]] = [rank+1,0,0,0,\"\"]\n",
    "    \n",
    "for rank, pers in enumerate(sort_neg):\n",
    "    char_ranks[pers[0]][1] = rank+1\n",
    "    if(char_ranks[pers[0]][1] < (char_ranks[pers[0]][0] - 4)):\n",
    "        char_ranks[pers[0]][4] = \"Negative\"\n",
    "    if(char_ranks[pers[0]][1] > (char_ranks[pers[0]][0] + 4)):\n",
    "        char_ranks[pers[0]][4] = \"Positive\"\n",
    "    net_pos_rank = char_ranks[pers[0]][1] - char_ranks[pers[0]][0]\n",
    "    char_ranks[pers[0]][3] = net_pos_rank\n",
    "    final_emot_rk[pers[0]] = net_pos_rank\n",
    "\n",
    "for rank, pers in enumerate(sort_emot):\n",
    "    char_ranks[pers[0]][2] = rank+1\n",
    "\n",
    "    \n",
    "print(char_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code chunk above, I also created a dictionary that maps a character to their net_ranking. This would correlate to, how much higher are they ranked in the 'percent of positive words' rankings than in the 'percent of negative words' rankings. This should give us a good idea of who is the most consistently positive (meaning without using a lot of negative words as well). The output is printed below. This is a similar list to the general sentiment score, with a few exceptions. In a list of 25 characters, this is not a very telling analysis. However, if we were to change the code to include all characters who spoke > 10 words, it would be hard to differentiate the people whose positive rank was 100 and negative rank was 700 as positive, but this method can help sort out these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rk)  Character   Net Positive\n",
      "1    David Wallace   17\n",
      "2    Ryan   17\n",
      "3    Holly   14\n",
      "4    Pam   11\n",
      "5    Angela   9\n",
      "6    Michael   8\n",
      "7    Jan   6\n",
      "8    Erin   6\n",
      "9    Deangelo   5\n",
      "10    Robert California   4\n",
      "11    Phyllis   4\n",
      "12    Nellie   3\n",
      "13    Andy   3\n",
      "14    Jim   3\n",
      "15    Kevin   -2\n",
      "16    Toby   -5\n",
      "17    Oscar   -6\n",
      "18    Kelly   -8\n",
      "19    Gabe   -9\n",
      "20    Darryl   -9\n",
      "21    Stanley   -14\n",
      "22    Dwight   -15\n",
      "23    Creed   -19\n",
      "24    Meredith   -23\n"
     ]
    }
   ],
   "source": [
    "sort_final = sorted(final_emot_rk.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Rk)  Character   Net Positive\")\n",
    "for rk, i in enumerate(sort_final):\n",
    "    print(rk+1,\"  \", i[0], \" \", i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This just writes the original {person : all text} dictionary to a to a txt file.\n",
    "\n",
    "header = [\"Character\", \"Words\"]\n",
    "with open('office-transcript.txt','w', encoding='utf-8') as out_file:\n",
    "    out_file.write('\\t'.join(header)+'\\n')\n",
    "    \n",
    "    for idx, key in enumerate(chardict):\n",
    "        outl = [key, str(chardict[key])]\n",
    "        \n",
    "        out_file.write('\\t'.join(outl) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "While there were not a lot of \"wow\" discoveries in this data analysis, I think that being able to pull raw json files of trascripts and properly dig through and classify them - then being able to confirm these results through analysis that would make complete sense to someone who watches the show is pretty cool.\n",
    "\n",
    "Some of the things I thought were cool takeaways were:\n",
    "\n",
    "- There were 700 unique characters who appeared on the office in all 9 seasons, and they spoke a total of > 620,000 words.\n",
    "- The main character Michael Scott spoke 159,101 words over the course of the show. This was 25.7% of the total words spoken on the show, and only appeared in the first 7 seasons (and 1 episode in season 9).\n",
    "- All of the main characters (>1000 spoken words), had sentiment scores of > 0.\n",
    "- 569 of the 700 unique characters (81.3%) only appeared in 1 of the 9 seasons of the show.\n",
    "- The expected positive and negative characters scored about exactly as a viewer would've expected, which is cool to see the confimation of the data and the accuracy of the sentiment classifier used.\n",
    "\n",
    "Some futures directions that someone could go with this analysis are:\n",
    "\n",
    "- Look at show sentiment (from all characters) for each specific episode. You could then create some visuals of the trends of the emotions thoughout the course of the show.\n",
    "- Look at how closely the sentiment of the the title of an episode matches with the sentiment of the show.\n",
    "- For characters that appear less frequently we could look at sentiments of the shows that they are in and see if they bring positive or negative emotions into the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
